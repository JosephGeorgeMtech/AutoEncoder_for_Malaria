{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQZIiVJ8vp3IBgv9AvsbUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosephGeorgeMtech/AutoEncoder_for_Malaria/blob/main/ConvAutoencoder_AnomalyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfLj1xZNirTw"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip '/content/drive/MyDrive/Malaria_dataset.zip' -d '/content/Malaria_datasett/'"
      ],
      "metadata": {
        "id": "mPF3IOBJixmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Size of our input images\n",
        "SIZE = 128"
      ],
      "metadata": {
        "id": "HbG3E8Vtixp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define generators for training, validation and also anomaly data.\n",
        "\n",
        "batch_size = 64\n",
        "datagen = ImageDataGenerator(rescale=1./255)#,rotation_range = 5, shear_range = 0.02,\\\n",
        "                             #zoom_range = 0.02, samplewise_center=True, \\\n",
        "                             #samplewise_std_normalization= True)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/Malaria_datasett/Malaria dataset/Uninfected_train/',\n",
        "    target_size=(SIZE, SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input'\n",
        "    )\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/Malaria_datasett/Malaria dataset/Uninfected_val/',\n",
        "    target_size=(SIZE, SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input'\n",
        "    )\n",
        "\n",
        "anomaly_generator = datagen.flow_from_directory(\n",
        "    '/content/Malaria_datasett/Malaria dataset/Infected/',\n",
        "    target_size=(SIZE, SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input'\n",
        "    )"
      ],
      "metadata": {
        "id": "H_exh22Oixso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the autoencoder. \n",
        "#Try to make the bottleneck layer size as small as possible to make it easy for\n",
        "#density calculations and also picking appropriate thresholds. \n",
        "\n",
        "#Encoder\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3)))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "#Decoder\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))"
      ],
      "metadata": {
        "id": "WGkj4uKkixvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "oHPiTnqNixyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model. \n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        \n",
        "        epochs=1000,\n",
        "        validation_data=validation_generator,\n",
        "        \n",
        "        shuffle = True)"
      ],
      "metadata": {
        "id": "qd8gXH8vix0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sslp6SVbix3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Lets get a batch of images. We have used DataGenrator, how it generates a batch of images? using .next()\n",
        "\n",
        "At the end of this, we will have all the batches. Each batch will contain 64 items.\n"
      ],
      "metadata": {
        "id": "RrZ6rdwGjHYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all batches generated by the datagen and pick a batch for prediction\n",
        "#Just to test the model. \n",
        "data_batch = []  #Capture all training batches as a numpy array\n",
        "img_num = 0\n",
        "while img_num <= train_generator.batch_index:   #gets each generated batch of size batch_size\n",
        "    data = train_generator.next()\n",
        "    data_batch.append(data[0])\n",
        "    img_num = img_num + 1\n",
        "\n",
        "print(len(data_batch))"
      ],
      "metadata": {
        "id": "PFkGqTQuix57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the list containing batches, we pick firts batch and do predictions."
      ],
      "metadata": {
        "id": "5GjXB0lcjiiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(data_batch[0])  #Predict on the first batch of images"
      ],
      "metadata": {
        "id": "KtQoNJXujK3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now going to predict on some random images"
      ],
      "metadata": {
        "id": "6vRW9DCbjhPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view few images and corresponding reconstructions\n",
        "image_number = random.randint(0, predicted.shape[0])\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(data_batch[0][image_number])\n",
        "plt.subplot(122)\n",
        "plt.imshow(predicted[image_number])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4gqAV7agjK67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us examine the reconstruction error between our validation data (good/normal images)\n",
        "# and the anomaly images\n",
        "validation_error = model.evaluate(validation_generator)\n",
        "anomaly_error = model.evaluate(anomaly_generator)\n",
        "\n",
        "print(\"Recon. error for the validation (normal) data is: \", validation_error)\n",
        "print(\"Recon. error for the anomaly data is: \", anomaly_error)"
      ],
      "metadata": {
        "id": "IpV8wvj3jK_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_anomaly(img_path):\n",
        "    \n",
        "    reconstruction_error_threshold = 0.0045 # Set this value based on the above exercise\n",
        "    img  = Image.open(img_path)\n",
        "    img = np.array(img.resize((128,128), Image.ANTIALIAS))\n",
        "    plt.imshow(img)\n",
        "    img = img / 255.\n",
        "    img = img[np.newaxis, :,:,:]\n",
        "    #encoded_img = encoder_model.predict([[img]]) \n",
        "    #encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] \n",
        "    #density = kde.score_samples(encoded_img)[0] \n",
        "\n",
        "    reconstruction = model.predict([[img]])\n",
        "    reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
        "\n",
        "    if reconstruction_error > reconstruction_error_threshold:\n",
        "        print(\"The image is an anomaly\")\n",
        "        \n",
        "    else:\n",
        "        print(\"The image is NOT an anomaly\")"
      ],
      "metadata": {
        "id": "VhkxbZI9jLBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a couple of test images and verify whether they are reported as anomalies.\n",
        "import glob\n",
        "para_file_paths = glob.glob('/content/Malaria_datasett/Malaria dataset/Infected/images/*')\n",
        "uninfected_file_paths = glob.glob('/content/Malaria_datasett/Malaria dataset/Uninfected_train/images/*')"
      ],
      "metadata": {
        "id": "UKYGbb6sjLEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Anomaly image verification\n",
        "num=random.randint(0,len(para_file_paths)-1)\n",
        "check_anomaly(para_file_paths[num])"
      ],
      "metadata": {
        "id": "7TEO3XPCjLGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Good/normal image verification\n",
        "num=random.randint(0,len(para_file_paths)-1)\n",
        "check_anomaly(uninfected_file_paths[num])"
      ],
      "metadata": {
        "id": "j1FVk5YpjYGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}